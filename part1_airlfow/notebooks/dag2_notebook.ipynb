{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции чистки данных для второго ДАГ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.providers.postgres.hooks.postgres import PostgresHook\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_duplicates(data: pd.DataFrame):\n",
    "    feature_cols = data.columns.drop('flat_id')\n",
    "    is_duplicated_features = data.duplicated(subset=feature_cols, keep=False)\n",
    "    if  len(data[is_duplicated_features]) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values(data: pd.DataFrame):\n",
    "    cols_with_nans = data.isnull().sum()\n",
    "    if cols_with_nans.any():\n",
    "        cols_with_nans = cols_with_nans[cols_with_nans > 0] # список имен столбцов с пропусками\n",
    "        return cols_with_nans.index.drop('target') if 'target' in cols_with_nans.index else cols_with_nans.index\n",
    "    else:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(cols_with_nans: pd.Series, data: pd.DataFrame):\n",
    "    for col in cols_with_nans:\n",
    "        if data[col].dtype in [float, int]:\n",
    "            fill_value = data[col].mean()\n",
    "        elif data[col].dtype == 'object':\n",
    "            fill_value = data[col].mode().iloc[0]\n",
    "\n",
    "        data[col] = data[col].fillna(fill_value)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(data: pd.DataFrame):\n",
    "    num_cols = data.select_dtypes(['float']).columns\n",
    "    threshold = 1.5\n",
    "    potential_outliers = pd.DataFrame()\n",
    "\n",
    "    for col in num_cols:\n",
    "        Q1 = data[col].quantile(0.25)\n",
    "        Q3 = data[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        margin = threshold * IQR\n",
    "        lower = Q1 - margin\n",
    "        upper = Q3 + margin\n",
    "        potential_outliers[col] = ~data[col].between(lower, upper)\n",
    "\n",
    "    outliers = potential_outliers.any(axis=1)\n",
    "    data = data[~outliers]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(data: pd.DataFrame):\n",
    "    feature_cols = data.columns.drop('flat_id').tolist()\n",
    "    is_duplicated_features = data.duplicated(subset=feature_cols, keep=False)\n",
    "    data = data[~is_duplicated_features].reset_index(drop=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(**kwargs):\n",
    "        hook = PostgresHook('destination_db')\n",
    "        conn = hook.get_conn()\n",
    "        table_name = kwargs.get('table_name')\n",
    "        sql = 'SELECT * FROM ' + table_name\n",
    "        data = pd.read_sql(sql, conn)\n",
    "        conn.close()\n",
    "        ti = kwargs['ti']\n",
    "        ti.xcom_push(key='extracted_data', value=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(**kwargs):\n",
    "        ti = kwargs['ti']\n",
    "        data = ti.xcom_pull(task_ids='extract', key='extracted_data')\n",
    "\n",
    "        if has_duplicates(data):\n",
    "            data = remove_duplicates(data)\n",
    "\n",
    "        cols_with_nans = missing_values(data)\n",
    "        if cols_with_nans:\n",
    "            data = fill_missing_values(cols_with_nans, data)\n",
    "        \n",
    "        data = remove_outliers(data)\n",
    "        \n",
    "        ti.xcom_push('transformed_data', data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_mle_sprint1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
